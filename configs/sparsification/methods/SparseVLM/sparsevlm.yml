base:
    seed: &seed 42
model:
    type: Llava
    path: model path
    torch_dtype: auto
eval:
    eval_pos: [pretrain, transformed]
    type: vqa
    name: [mme]
    download: False
    path: MME dataset path
    bs: 1
    inference_per_block: False
sparse:
    method: TokenReduction
    special:
        method: SparseVLM
        pruning_loc: [2, 6, 15]
        retained_tokens: 192
        prune_flag: True
        merge_flag: True
save:
    save_trans: False
    save_fake: False
    save_path: /path/to/save/
